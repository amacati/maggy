{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Training ResNet50 with distributed training on Maggy\n",
    "In this notebook we will train a ResNet50 model from scratch with data from ImageNette. Note that a PyTorch Dataset and DataLoader is employed which results in large I/O overhead and doesn't fully utilize the GPU capabilities. For higher throughput, see ImageNette_petastorm.ipynb."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "from torchvision import models, datasets\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from hops import hdfs"
   ]
  },
  {
   "source": [
    "## Creating the PyTorch Dataset\n",
    "The metadata of our dataset is stored in a .csv file located in the root folder. It contains the labels of each image and its source path. For convenience, we relabel the classes into integers. In the `__getitem__` function, we enable custom transformations after reading the image and its label. The advantage of defining our own dataset is that we have no problems performing I/O operations on our DFS, which would fail when simply calling `os.open()` (which is what PyTorch's predefined datasets do). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNetDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, path, transform=None, test_set=False):\n",
    "        super().__init__()\n",
    "        self.root = path\n",
    "        self.df = pd.read_csv(path + \"noisy_imagenette.csv\")\n",
    "        self.transform = transform\n",
    "        if test_set:\n",
    "            self.df = self.df[self.df.is_valid]\n",
    "        else:\n",
    "            self.df = self.df[self.df.is_valid == False]\n",
    "        self.df.drop([\"noisy_labels_\" + str(i) for i in [1, 5, 25,50]], axis=1, inplace=True)\n",
    "        self.labels = {\"n01440764\": 0,  # \"tench\" \n",
    "                       \"n02102040\": 1,  # \"English springer\"\n",
    "                       \"n02979186\": 2,  # \"cassette player\"\n",
    "                       \"n03000684\": 3,  # \"chain saw\"\n",
    "                       \"n03028079\": 4,  # \"church\"\n",
    "                       \"n03394916\": 5,  # \"French horn\"\n",
    "                       \"n03417042\": 6,  # \"garbage truck\"\n",
    "                       \"n03425413\": 7,  # \"gas pump\"\n",
    "                       \"n03445777\": 8,  # \"golf ball\"\n",
    "                       \"n03888257\": 9,  # \"parachute\"\n",
    "                      }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        label = self.labels[row[\"noisy_labels_0\"]]\n",
    "        f = hdfs.open_file(self.root + row[\"path\"])\n",
    "        try:\n",
    "            img = Image.open(f).convert(\"RGB\")\n",
    "        finally:\n",
    "            f.close()\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        sample = {\"image\": img, \"label\": label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = hdfs.project_path() + \"DataSets/ImageNet/imagenette/\""
   ]
  },
  {
   "source": [
    "## Defining data transforms\n",
    "To increase the variety of our training samples, we employ data augmentation via torchvision's transforms API. For training images, in addition to resizing and randomly cropping, we also flip images horizontally. In the test set, we use a center crop and no flips to remove randomness. All images are normalized for numeric convenience."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = T.Compose(\n",
    "    [T.Resize(256),\n",
    "     T.RandomCrop(224),\n",
    "     T.RandomHorizontalFlip(),\n",
    "     T.ToTensor(),\n",
    "     T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "test_transform = T.Compose(\n",
    "    [T.Resize(256),\n",
    "     T.CenterCrop(224),\n",
    "     T.ToTensor(),\n",
    "     T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ImageNetDataset(path, transform=train_transform)\n",
    "test_ds = ImageNetDataset(path, transform=test_transform, test_set=True)"
   ]
  },
  {
   "source": [
    "## Defining the training function\n",
    "In order to use PyTorch with maggy, we need to define our training loop in a function. The function takes our module, its hyperparameters and both the train and test set as input. Note that the module should be a class that is instantiated in our training loop, since transferring the model weights at the beginning of the loop would result in a huge communicational overhead. Likewise, it is not advised to use datasets with large memory footprint over the function, but rather load it from the DFS when requested.\n",
    "Inside the training loop it is **mandatory for maggy** to use a torch DataLoader. Apart from these restrictions, you can freely implement your training loop as in normal PyTorch. Finally, we have to import all of the used libraries inside the function."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(module, hparams, train_set, test_set):\n",
    "    \n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import time\n",
    "    from torch.utils.data import DataLoader\n",
    "    from hops import hdfs\n",
    "    \n",
    "    model = module(**hparams)\n",
    "    \n",
    "    n_epochs = 3\n",
    "    lr = 0.01\n",
    "    batch_size = 64\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_loader = DataLoader(train_set, pin_memory=True, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_set, pin_memory=True, batch_size=batch_size, drop_last=True)\n",
    "    \n",
    "    def print_peak_memory(prefix):\n",
    "        print(f\"{prefix}: {torch.cuda.max_memory_allocated(0) // 1e6}MB \")\n",
    "                \n",
    "    def time_to_h_m_s(t_diff):\n",
    "        minutes, seconds = divmod(t_diff, 60)\n",
    "        hours, minutes = divmod(minutes, 60)\n",
    "        return hours, minutes, seconds\n",
    "\n",
    "    def print_train_time(t_0, batch, n_batches, epoch, n_epochs):\n",
    "        t_diff = time.time() - t_0\n",
    "        tr_time = time_to_h_m_s(t_diff)\n",
    "        t_est = t_diff * (n_epochs*n_batches/(epoch*n_batches + idx+1) - 1)\n",
    "        est_time = time_to_h_m_s(t_est)\n",
    "        print(\"Training time: {:.0f}h {:.0f}m {:.0f}s\\nEstimated remaining time: {:.0f}h {:.0f}m {:.0f}s.\".format(*tr_time, *est_time))\n",
    "\n",
    "    def eval_model(model, test_loader):\n",
    "        acc = 0\n",
    "        model.eval()\n",
    "        img_cnt = 0\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                img, label = data[\"image\"], data[\"label\"]\n",
    "                prediction = model(img)\n",
    "                acc += torch.sum(torch.argmax(prediction, dim=1) == label)\n",
    "                img_cnt += len(label)\n",
    "        acc = acc.detach()/float(img_cnt)\n",
    "        print(\"Test accuracy: {:.3f}\".format(acc))\n",
    "        print(\"-\"*20)\n",
    "        return acc\n",
    "\n",
    "    model.train()\n",
    "    t_0 = time.time()\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"-\"*20 + \"\\nStarting new epoch\\n\")\n",
    "        t_start = time.time()\n",
    "        td_start = t_start\n",
    "        for idx, data in enumerate(train_loader):\n",
    "            td_end = time.time()\n",
    "            # print(f\"DataLoader load time: {td_end - td_start}\")\n",
    "            img, label = data[\"image\"], data[\"label\"]\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(img)\n",
    "            output = loss_criterion(prediction, label.long())\n",
    "            output.backward()\n",
    "            optimizer.step()\n",
    "            if idx%(int(len(train_loader)/10)) == 0:\n",
    "                print(f\"Working on batch {idx}/{len(train_loader)}\")\n",
    "                print_peak_memory(\"Memory consumed during training step\")\n",
    "                print_train_time(t_0, idx, len(train_loader), epoch, n_epochs)\n",
    "            td_start = time.time()\n",
    "            print(f\"Training time: {td_start - td_end}\")\n",
    "        t_end = time.time()\n",
    "        print(\"Epoch training took {:.0f}s.\\n\".format(t_end-t_start))\n",
    "        acc = eval_model(model, test_loader)\n",
    "    t_1 = time.time()\n",
    "    minutes, seconds = divmod(t_1 - t_0, 60)\n",
    "    hours, minutes = divmod(minutes, 60)\n",
    "    print(\"-\"*20 + \"\\nTotal training time: {:.0f}h {:.0f}m {:.0f}s.\".format(hours, minutes, seconds))\n",
    "    return float(acc)"
   ]
  },
  {
   "source": [
    "## Configuring maggy\n",
    "As a last step, we need to configure our maggy experiment. Here we pass our model class, our train and test dataset as well as the desired backend. Maggy supports either `ddp` or `deepspeed`, with additional constraints on deepspeed. If using ddp, you can employ the PyTorch version of the ZeRO optimizer by changing your optimizer in the training function, and go to level 3 with changing the ZeRO level in the config."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maggy import experiment\n",
    "from maggy.experiment_config import TorchDistributedConfig\n",
    "\n",
    "config = TorchDistributedConfig(name='ImageNette_benchmark', module=models.resnet50, train_set=train_ds, test_set=test_ds, backend=\"ddp\")"
   ]
  },
  {
   "source": [
    "## Running the experiment\n",
    "Now that everything is configured, we are ready to run the experiment by calling the lagom function. You should be able to see the output of your workers in the notebook."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = experiment.lagom(train_fn, config)"
   ]
  }
 ]
}
